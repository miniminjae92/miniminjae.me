---
title: "불확실한 세상에서 예측하는 법"
slug: statistics-ai
date: 2024-10-04 19:36
description: "AI·통계·머신러닝을 한 번에 꿰어 보기"
tags:
  - 통계
  - AI
---

# 불확실한 세상에서 예측하는 법  
AI·통계·머신러닝을 한 번에 꿰어 보기

> 아직 제대로 배우기 전,  
> **“지금 내가 이해하고 있는 그림”**을 기록해 두고  
> 나중에 다시 비교해 보려는 메모 겸 인사이트 글이다.

---

## 0. Python, NumPy는 왜 자꾸 등장할까

내가 앞으로 공부하려는 **Python(파이썬)** 과 **NumPy(넘파이)** 는  
사실 “또 하나의 언어, 또 하나의 라이브러리”가 아니라,

> **데이터·확률·벡터·행렬을 손으로 만지작거리게 해주는 실험 도구**

라고 느껴진다.  
이 글에 나오는 개념들은 결국 **Python + NumPy로 직접 계산하고 실험해 보기 위한 사고 틀**을 정리한 것이다.

---

## 1. AI → Machine Learning → Deep Learning

먼저 큰 지도를 그려 놓자.

- **AI(Artificial Intelligence, 인공지능)**  
  → 인간의 “지능적인 행동”을 흉내 내는 모든 기술

- **Machine Learning(머신러닝)**  
  → 데이터를 보고 **스스로 패턴을 학습**해서  
    앞으로 들어올 데이터를 **예측**하려는 기술

- **Deep Learning(딥러닝)**  
  → **인공 신경망(Artificial Neural Network)** 을 여러 층 깊게 쌓아서  
    훨씬 복잡한 패턴까지 학습하는 머신러닝의 한 종류

머신러닝의 학습 방식은 대략 이렇게 나뉜다.

1. **Supervised Learning(지도 학습)** – 정답(Label)이 있는 데이터  
   - **Classification(분류)**: 스팸/햄, 정상/불량처럼 “종류”를 맞히기  
   - **Regression(회귀)**: 집값, 온도처럼 “연속적인 숫자”를 맞히기  

2. **Unsupervised Learning(비지도 학습)** – 정답이 없는 데이터  
   - **Clustering(군집화)**: 비슷한 것끼리 묶기  
   - **Dimensionality Reduction(차원 축소)**: 정보는 유지하면서  
     특징 수(차원)를 줄여 보기

3. **Reinforcement Learning(강화 학습)**  
   - 환경에서 행동을 하고 **Reward(보상)** 을 받으면서  
     장기적으로 보상을 최대화하는 방향으로 정책을 배우는 방식

---

## 2. 통계적 사고: “세상 전체를 다 볼 수 없으니까”

통계는 결국 이런 인식에서 출발하는 것 같다.

> 세상 전체(모집단)를 모두 측정할 수 없으니,  
> **일부(표본)** 만 보고 전체를 **추론**해야 한다.

- **Population(모집단)**: 내가 관심 있는 전체 집단  
- **Sample(표본)**: 잘 섞어서 뽑은 일부 – “간 보듯이 떠온 국물 한 숟갈”

우리가 하는 일은:

1. 표본에서 **요약 통계(summary)** 를 계산한다.  
   - 평균(Mean), 중앙값(Median), 분산(Variance) 같은 숫자들
2. 이 숫자로 **모집단의 모수(parameter)** 를 **추정(estimation)** 한다.
3. 세상이 본질적으로 **불확실(uncertainty)** 하기 때문에  
   그 불확실함을 **확률(Probability)** 로 표현한다.
4. 그리고 **“이 현상이 우연인가, 진짜 효과인가?”** 를 묻는 게  
   **가설검정(Hypothesis Test)** 이다.

### 귀무가설, 유의성, 그리고 두 가지 오류

- **귀무가설(Null Hypothesis, H₀)**: “아무 효과가 없다”라는 기본 입장  
- **대립가설(Alternative Hypothesis, H₁)**: “무언가 효과가 있다”라는 주장

우리는 보통 이렇게 생각한다.

> “정말로 아무 효과가 없다(H₀가 참)고 가정했을 때,  
> 지금 같은 결과가 나올 확률이 너무 낮다면,  
> 이것은 ‘우연’이라고 보기 힘들다 → 효과가 있다고 보자.”

이때 등장하는 **두 가지 오류**:

- **제1종 오류(Type I Error)**  
  - 사실은 **효과가 없는데**(H₀ 참) **있다고 판단**  
  - 예: 무죄인 사람을 유죄로 판결  
  - 법에서는 이걸 더 치명적으로 보고,  
    “무죄추정의 원칙”으로 제1종 오류를 줄이는 데 민감하다.

- **제2종 오류(Type II Error)**  
  - 사실은 **효과가 있는데**(H₁ 참) **없다고 판단**  
  - 예: 암 환자를 건강하다고 보는 경우  
  - 제조, 의료 같은 분야에선 이 오류를 더 무겁게 본다.

여기까지가 통계가 세상을 바라보는 기본 관점이다.  
이제 이 시선이 머신러닝으로 어떻게 이어지는지 보자.

---

## 3. Error, Loss, Cost – “틀림”을 숫자로 다루는 법

모델을 만들면 **예측값(ŷ)** 과 **실제값(y)** 사이에 항상 차이가 생긴다.

- **Error / Residual(오차/잔차)**  
  - 개별 데이터에 대한 차이: `예측값 - 실제값`  
  - 통계에서는 주로 **Residual**, 딥러닝에서는 **Error** 라고 부르곤 한다.

- **Loss(손실)**  
  - 한 개 데이터의 Error가 **얼마나 나쁜지**를 점수로 바꾼 것  
  - 예:  
    - L1 Loss(MAE): `|Error|`  
    - L2 Loss(MSE): `Error²`

- **Cost(비용)**  
  - **데이터 전체에 대한 Loss의 평균**  
  - “이 모델이 전체적으로 얼마나 못하고 있는가?”를 나타내는 대표 점수  
  - 딥러닝의 목표는 결국 **이 Cost를 최소화**하는 것

학습 과정은 이 한 줄로 요약된다.

> **Forward Propagation(순전파)** → Loss 계산 →  
> **Backward Propagation(역전파)** → Weight Update(가중치 조정)

Python + NumPy는 이 **Error, Loss, Cost** 를 눈앞에서 직접 계산하고,  
가중치를 조금씩 바꿔 가면서 줄여 나가는 실험 도구가 된다.

---

## 4. 과적합(Overfitting): 너무 잘 외워서 망하는 모델

머신러닝 모델의 영원한 적.

> **훈련 데이터만 기가 막히게 외워서,  
> 새로운 데이터에선 허당이 되는 현상**

이를 줄이기 위한 대표적인 전략들:

- **Regularization(규제)**  
  - 가중치가 과하게 커지지 않도록 **패널티**를 주는 방식  
  - L1, L2 규제가 대표적

- **Ensemble(앙상블)**  
  - 여러 모델을 함께 쓰는 것  
  - **Bagging, Boosting, Stacking**  
  - 서로 다른 모델을 섞어 **노이즈를 상쇄**하고 안정화

- **Dropout(드롭아웃)**  
  - 딥러닝에서 학습 중 **일부 뉴런을 랜덤으로 꺼 버리는** 기법  
  - 특정 경로에만 너무 의존하지 않게 한다.

- **Early Stopping(조기 종료)**  
  - 검증 데이터 성능이 더 이상 좋아지지 않을 때  
    과감히 학습을 멈추는 방법

- **Data Augmentation(데이터 증강)**  
  - 이미지 뒤집기, 회전, 노이즈 추가처럼  
    데이터를 변형해서 **사실상 데이터 양을 늘리는** 기법

결국 핵심은 한 줄이다.

> “**훈련 세트를 잘 맞추는 능력과,  
> 처음 보는 데이터에 잘 일반화하는 능력 사이의 균형**”

---

## 5. 분류(Classification) 모델을 평가하는 시선

### 5-1. Accuracy(정확도)의 함정

- 정확도 = 전체 중 맞춘 비율  
- 데이터가 **불균형(imbalanced)** 하면 완전히 속을 수 있다.

예: 100명 중 99명은 정상, 1명만 암 환자.  
모든 사람을 “정상”이라 예측해도 정확도는 99%다.  
하지만 이 모델은 **암 환자를 단 한 명도 찾지 못하는 쓸모없는 모델**이다.

### 5-2. Confusion Matrix(오차 행렬)

정확도의 함정을 피하려면 “어디서 어떻게 틀리고 있는지”를 봐야 한다.

|                | **예측 Positive** | **예측 Negative** |
|----------------|-------------------|-------------------|
| **실제 Positive** | TP (True Positive) | FN (False Negative) |
| **실제 Negative** | FP (False Positive) | TN (True Negative) |

- **TP**: 진짜 양성 잘 맞춤 (암 환자를 암이라고 예측)  
- **TN**: 진짜 음성 잘 맞춤 (정상인을 정상이라고 예측)  
- **FP**: 가짜 양성 – 정상인을 암이라고 (멀쩡한 사람 잡음)  
- **FN**: 가짜 음성 – 암 환자를 정상이라고 (잡아야 할 걸 놓침)

여기서부터 **Precision(정밀도)** 와 **Recall(재현율)** 이 나온다.

### 5-3. Precision(정밀도)

- 수식:  
$$
  Precision = \frac{TP}{TP + FP}
$$
- “**내가 Positive라고 예측한 것들 중에,  
  실제로 Positive인 비율**”
- **FP를 줄이는 게 중요한 상황**에서 중요  
  - 예: 스팸 필터 – 정상 메일을 스팸으로 잘못 막으면 큰일

### 5-4. Recall(재현율)

- 수식:  
$$
  Recall = \frac{TP}{TP + FN}
$$
- “**실제 Positive 중에서,  
  내가 Positive라고 잡아낸 비율**”
- **FN을 줄이는 게 중요한 상황**에서 중요  
  - 예: 암 진단, 불량품 검출 – 놓치는 게 더 치명적

### 5-5. F1-Score

- Precision과 Recall의 **조화 평균(harmonic mean)**
- 한쪽만 높고 다른 한쪽이 바닥이면 F1도 낮다.  
- 데이터가 불균형할 땐 **Accuracy보다 F1을 보는 게 훨씬 건강한 평가**다.

### 5-6. ROC Curve & AUC

- **ROC Curve(Receiver Operating Characteristic Curve)**  
  - Threshold(임계값)를 0→1로 바꿔 가며  
    FPR(False Positive Rate) vs TPR(True Positive Rate, Recall)을 그린 곡선

- **AUC(Area Under the Curve)**  
  - ROC 곡선 아래 면적  
  - 1에 가까울수록 Positive/Negative를 잘 구분하는 모델

---

## 6. 회귀(Regression) 모델을 평가하는 시선

회귀는 “얼마냐?”를 맞히는 게임이다.  
관심사는 **예측값이 실제값과 얼마나 가깝냐**이다.

- **MAE(Mean Absolute Error, 평균 절대 오차)**  
    $$
    MAE = \frac{1}{n}\sum |y_i - \hat{y}_i|
    $$
  - 직관적이고, 이상치(Outlier)에 덜 민감

- **MSE(Mean Squared Error, 평균 제곱 오차)**  
    $$
    MSE = \frac{1}{n}\sum (y_i - \hat{y}_i)^2
    $$
  - 오차를 제곱하니, 큰 오차에 더 큰 벌점

- **RMSE(Root Mean Squared Error, 제곱근 평균 제곱 오차)**  
    $$
    RMSE = \sqrt{MSE}
    $$ 
  - 단위가 원래 데이터와 같아져서 해석이 편하다.

- **R²(결정계수)**  
  - 대략  
    > “모델이 데이터 변동성의 몇 %를 설명하고 있는가?”  
  - `\(R^2 = 0.8\)` 이라면 → “이 모델이 데이터의 변동 80%를 설명한다.”

---

## 7. Cross-Validation(교차 검증): 우연한 성적을 피하는 방법

데이터를 한 번만 훈련/검증으로 나누면,  
우연히 **쉬운 검증 세트**를 뽑았을 수도 있다.

그래서 많이 쓰는 방법이 **K-Fold Cross-Validation(케이겹 교차 검증)**.

1. 데이터를 K개로 나눈다.  
2. 그중 1개를 검증, 나머지 K-1개를 훈련으로 사용.  
3. 폴드를 바꿔 가며 K번 반복.  
4. K개의 점수를 평균 내서 **모델의 일반화 성능**으로 본다.

통계에서 말하는  
“**한 번만 던진 주사위로 세상을 판단하지 말자**”는 태도를  
그대로 모델 평가에 가져온 셈이다.

---

## 8. 한 줄 요약

- **AI** 는 “지능 흉내 내는 모든 것”,  
  **Machine Learning** 은 “데이터에서 패턴을 배우는 것”,  
  **Deep Learning** 은 그중 **신경망 기반**.

- **통계** 는 “일부(표본)를 보고 전체(모집단)를 추론하는 기술”이고,  
  그 과정에서 **불확실성을 확률로 표현**하며,  
  **Type I/II Error** 사이의 우선순위를 도메인에 따라 다르게 둔다.

- 모델은 항상 틀리고,  
  그 틀림을 **Error → Loss → Cost** 로 수치화해서  
  **최소화하는 방향으로 가중치를 조정**한다.

- **과적합** 은 “외우기만 잘한 모델”이고,  
  규제, 앙상블, 드롭아웃, 조기 종료, 데이터 증강으로  
  **기억과 일반화 사이의 균형**을 맞추려 한다.

- **분류** 에서는 Accuracy 대신  
  **Confusion Matrix, Precision, Recall, F1, ROC-AUC** 로  
  “어디서 어떻게 틀리고 있는지”를 본다.

- **회귀** 에서는 MAE, MSE, RMSE, R² 로  
  “얼마나 가깝게 맞히고 있는지”를 본다.

- **교차 검증** 은  
  “우연히 쉬운 시험을 봤을 뿐인지”를 체크하는 안전장치다.

