---
title: "빅데이터, 추천 시스템, 시각화"
slug: bigdata-recommendsystem
date: 2024-10-04 20:15
description: "데이터로 세상을 읽는 몇 가지 관점"
tags:
  - Bigdata
---

# 빅데이터, 추천 시스템, 시각화  

데이터로 세상을 읽는 몇 가지 관점

> “빅데이터를 제대로 배우기 전,  
> 지금 내가 이해한 수준을 한 번 정리해 두는 글”  

나중에 실제로 데이터를 다루고 모델을 돌려 본 뒤,  
이 글을 다시 읽어보면 어떤 부분은 촌스럽고, 어떤 부분은 더 깊게 보일 것이다.  
그 차이가 곧 성장의 기록이 될 거라 생각한다.

---

## 1. 빅데이터: 21세기의 원유

**빅데이터(Big Data)** 를 한 문장으로 요약하면:

> **크고(Volume), 다양하며(Variety), 빠르게 쌓이고(Velocity),  
> 신뢰성과 진짜 가치(Veracity, Value)를 함께 고민해야 하는 데이터**

요즘 세상에서는 거의 모든 활동이 흔적을 남긴다.

- 검색 기록, 위치 기록, 결제 내역, SNS 활동, 센서 데이터…
- 이 모든 것이 **수집 → 저장 → 분석**되며,  
  그 안에서 **패턴과 통찰(Insight)** 을 뽑아내는 것이 핵심 과제다.

흐름만 보면 이렇게 이어진다.

> 인쇄 대중화 → 책, 도서관  
> → 인터넷, 검색의 시대  
> → 스마트폰, 모빌리티, 메타버스  
> → “모든 것이 데이터가 되는 시대”

그래서 자주 나오는 비유가 있다.

> **“빅데이터는 21세기의 원유(oil)”**

하지만 원유는 **그냥 땅속에 있다고 바로 가치가 되는 게 아니다.**  
꺼내고, 정제하고, 가공하고, 제품으로 만들어야 의미가 생긴다.  
빅데이터도 마찬가지다.

---

## 2. DIKW 피라미드: 물 → 생수병 → 우물 → 우물을 파는 법

**DIKW 피라미드(Data–Information–Knowledge–Wisdom)** 를  
내가 이해한 방식으로 풀어보면:

- **Data(데이터)** = 물  
  - 여기저기 흩어져 있는, 처리되지 않은 **그냥 물**
- **Information(정보)** = 생수병의 물  
  - 정리되고 라벨이 붙은 물  
  - “어디 물이고, 언제 떠온 물인지”가 적혀 있다.
- **Knowledge(지식)** = 우물 안의 물  
  - 반복적으로 사용할 수 있는 **구조화된 정보**  
  - “이 동네 사람들은 이 우물에서 물을 길어 쓴다.”
- **Wisdom(지혜)** = 우물을 파는 법  
  - 상황이 바뀌어도 적용 가능한 **원리, 원칙, 노하우**  
  - “어디에, 어떻게 우물을 파야 하는지 아는 것”

빅데이터의 일은 결국,

> **Data(물)를 모으고 → Information(생수)로 정리한 뒤 →  
> Knowledge(우물)를 만들고 →  
> 마지막에는 “어디에 우물을 파야 하는가”라는 Wisdom까지 가는 과정**

이라고 볼 수 있다.

---

## 3. 빅데이터 vs 전통 통계: 절차 중심 vs 결과 중심

빅데이터 시대 이전의 통계는 **데이터 자체를 얻기가 어려웠다.**

- 실험 설계(Design of Experiments)  
- 표본 조사(Sampling)  
- 공정한 설계 + 양질의 데이터  
- 그 위에서 돌아가는 통계 모형

이 세계관은 **“절차 중심”** 이었다.

> 데이터를 어떻게 모았는가?  
> 표본이 모집단을 잘 대표하는가?  
> 인과 관계를 어떻게 확인할 것인가?

반면, 빅데이터 세계에서는 상황이 다르다.

- 로그가 자동 수집되고
- 데이터가 “많다”는 것 자체로 **분산(variance)** 은 크게 줄어든다.
- 대신 **편의(bias, 편향)** 가 숨어 들어가기 쉽다.
  - 특정 사용자만 과대표집
  - 특정 행동만 과도하게 기록

그리고 목표도 조금 바뀐다.

- **전통 통계**: 인과 구조(causality), 모수 추정, 유의성 검정  
- **빅데이터/머신러닝**: **상관관계(correlation)** 와 **예측력(prediction)** 중심  
  - “왜”보다 “얼마나 잘 맞추는가”에 더 관심

이 말은 곧,

> **“빅데이터는 인과를 버려도 된다”가 아니라,  
> “예측력만 보고 의사결정을 하면  
> 편향을 놓치고 큰 비용을 치를 수 있다”** 는 경고로 이해해야 한다.

---

## 4. 자연어 처리(NLP): 언어를 벡터로 바꾸는 기술

**NLP(Natural Language Processing, 자연어 처리)** 는  
텍스트와 음성을 **데이터로 가공해서 의미를 다루는 분야**다.

### 4-1. 주요 활용

- 텍스트 요약, 분류
- 감성 분석(긍·부정, 감정)
- 의미 연결망 분석
- 기계 번역
- 질의응답, 챗봇
- 음성 인식

### 4-2. 핵심 아이디어

NLP의 기본 작업만 정리해 보면:

- **Tokenization(토큰화)**: 문장을 단어, subword 등 단위로 자르기  
- **Normalization(정규화)**: 소문자 변환, 불필요한 기호 제거 등  
- **Word Embedding(단어 임베딩)**:  
  단어를 벡터 공간에 매핑해서,  
  **“비슷한 단어는 비슷한 좌표”** 를 갖도록 만드는 것
- **Frequency(빈도)**: 단어가 얼마나 자주 나오는지  
- **Language Model(언어 모델)**:  
  “다음 단어가 뭐가 나올 것 같은지”를 예측하는 확률 모형

결국 NLP는,

> **언어를 수치화해서,  
> 통계와 머신러닝이 이해할 수 있는 형태로 바꾸는 과정**

이라고 정리할 수 있다.

---

## 5. 데이터 시각화: 정직·간결·정확

데이터를 그림으로 보여 줄 때,  
내가 기억해 두고 싶은 세 가지 키워드는:

> **Honesty(정직)**  
> **Simplicity(간결)**  
> **Accuracy(정확)**

- 정직: 보고 싶은 결과를 위해  
  축을 왜곡하거나 일부를 잘라내지 않기
- 간결: 불필요한 장식 대신  
  **메시지가 바로 보이게** 만들기
- 정확: 스케일, 색상, 범례 등  
  숫자와 시각 요소가 일관되도록

### 5-1. 시간 시각화

**시간의 흐름과 경향(trend)** 을 보는 데는:

- 선 그래프(line)
- 막대 그래프(bar)
- 점/버블 그래프(scatter/bubble)
- 누적 그래프(stacked)

같은 도구들이 쓰인다.

한스 로슬링(Hans Rosling)의 **Gapminder** 와  
《팩트풀니스(Factfulness)》는  
**“잘 만든 시각화가 세계관까지 바꿀 수 있다”** 는 걸 보여주는 좋은 예다.

### 5-2. 텍스트 & 네트워크 시각화

- **텍스트 시각화**  
  - WordCloud(단어 구름)  
  - WordTree(문장 구조 시각화 등)

- **소셜 네트워크 시각화**  
  - 방향성 있는/없는 그래프 (directed/undirected)  
  - Node/Vertex(노드), Edge/Link(관계)  
  - Degree(연결 수), 가중치(weight) 등

### 5-3. 도구들

- **R**: `ggplot2`  
- **Python**: `pandas`, `matplotlib`, `seaborn`, `plotly`  
- **웹/인터랙티브**: JavaScript + D3.js  
- **BI 도구**: Tableau, PowerBI

결국 도구보다 중요한 건 이 질문이다.

> “이 그래프를 본 사람이  
> **무엇을 오해하지 않고,  
> 무엇을 바로 이해하길 원하는가?**”

---

## 6. 추천 시스템: 상관관계로 취향을 예측하는 법

**Recommendation System(추천 시스템)** 은  
사용자에게 **“좋아할 만한 것”을 미리 던져주는 모델**이다.

크게 두 가지 관점으로 볼 수 있다.

1. **Associative Analysis(연관성 분석, Association Rule)**  
   - “이 상품을 산 사람은 저 상품도 함께 산다”  
   - 모집단 전체의 **규칙 X → Y** 를 찾는 방식

2. **Collaborative Filtering(협업 필터링)**  
   - **“나와 비슷한 사람”** 이 좋아한 것을 나도 좋아할 확률을 이용  
   - 사용자·아이템의 유사도를 계산해 추천

### 6-1. 연관성 분석의 세 가지 지표

규칙 `X → Y` 에 대해:

- **Support(지지도)**  
  - `P(X ∩ Y)`  
  - 전체 중 X와 Y가 함께 발생한 비율

- **Confidence(신뢰도)**  
  - `P(Y | X) = P(X ∩ Y) / P(X)`  
  - X가 발생했을 때, Y도 함께 일어날 확률

- **Lift(향상도)**  
  - `Lift = Confidence / P(Y)`  
  - “그냥 Y가 나올 확률” 대비  
    “X가 나왔을 때 Y가 나올 확률”이  
    얼마나 더 높은지(또는 낮은지)를 보는 지표

해석은 이렇게 정리된다.

- **Lift = 1** → X와 Y는 **독립**  
- **Lift > 1** → 양의 상관 관계(같이 잘 등장)  
- **Lift < 1** → 음의 상관 관계(같이 잘 안 나옴)

### 6-2. 유사도를 보는 두 시선

추천에서 자주 쓰이는 두 개념:

- **Cosine Similarity(코사인 유사도)**  
  - 벡터의 **방향**에 집중  
  - 크기보다 “같은 방향을 가리키는지”가 중요

- **Correlation(상관계수)**  
  - 각 차원에서의 **편차 패턴이 얼마나 비슷한지**  
  - 평균 대비 위/아래로 움직이는 양상이 비슷한지 본다.

둘 다 “얼마나 비슷한지”를 재지만  
**무엇을 비슷하다고 볼지**에 대한 관점이 다르다.

### 6-3. 데이터 희소성(Sparsity)

추천 시스템의 특징 중 하나는 **희소한 행렬**이다.

- 대부분의 사용자–상품 조합은 **아무 기록도 없다.**
- 이때 전략은 두 가지:

1. **상품 수 < 고객 수 → 상품 중심(Item-based) 방법**  
   - 해석력이 좋다. “이 상품을 좋아하면 저 상품도 좋아할 것”

2. **상품 수 > 고객 수 → 고객 중심(User-based) 방법**  
   - “나와 비슷한 사람”을 찾는 데 유리  
   - 때로는 더 **놀라운 추천(Serendipity)** 을 줄 수 있다.

---

## 7. 추천 시스템 평가: Precision vs Recall, 그리고 A/B 테스트

추천 시스템에서도 **Precision과 Recall** 의 trade-off가 등장한다.

- **Precision(정확도)**  
  - 추천한 것들 중, 실제로 사용자가 좋아한 것의 비율  
  - 높으면 “**헛발질이 적다**”  
  - → 사용자는 시스템을 **신뢰하게 된다.**

- **Recall(재현율)**  
  - 사용자가 실제로 좋아하는 것들 중,  
    우리가 추천에 포함시킨 비율  
  - 높으면 “**놓치지 않고 많이 보여준다**”  
  - → 사용자에게 **새로운 것, 다양한 것**을 보여 줄 수 있다.

여기서 자연스러운 질문이 나온다.

> “정확도도 높고, 재현율도 높게 만들 수는 없을까?”

이론적으로는:

- 모델이 충분히 좋고
- 데이터가 충분하며
- 추천 리스트를 넉넉히 보여줄 수 있다면

**Precision과 Recall을 동시에 끌어올리는 것도 가능**하다.  
하지만 실제 서비스에서는:

- 추천 슬롯(화면에 보여줄 자리)이 제한적이고
- 너무 많이 보여주면 사용자가 피곤해지고
- 비즈니스 목표(매출, 체류시간, 이탈률 등)에 따라  
  어느 쪽을 더 중시할지가 달라진다.

그래서 현실적인 결론은:

> **“둘 다 최대”가 아니라  
> **“우리 서비스에서 가장 좋은 타협점”을 찾는 문제**로 보는 게 맞다.**

### 7-1. 상대적 평가 vs 절대적 평가

추천 시스템 평가에는 두 층위가 있다.

1. **상대적 평가(Relative Evaluation)**  
   - 여러 모델을 비교해서  
     “어느 쪽의 예측력이 더 좋은지” 보는 것  
   - 오프라인 지표(F1, MAP, NDCG 등)를 많이 사용

2. **절대적 평가(Absolute Evaluation)**  
   - 비즈니스 관점에서 성과를 평가  
   - 실제 매출, 클릭률, 체류 시간, 이탈률 등

이 절대적 평가의 대표적인 방법이 **A/B Test**다.

- 추천 시스템을 **적용한 그룹(A)** 과  
  적용하지 않은 그룹(B)을 나누고
- 일정 기간 동안 두 그룹의 매출, 행동 지표를 비교한다.

문제는, 이 실험이 **비용이 드는 실험**이라는 점이다.

- 추천을 안 받은 그룹(B)은  
  실제로 **매출이 낮아질 수 있다.**
- 실험 기간 동안의 손실을 감수해야 한다.

그래서 현실적인 전략은:

> **1단계: 상대적 평가(오프라인)로 후보를 줄이고**  
> **2단계: 소수 후보 모델만 A/B Test로 절대 평가**  
> 를 수행하는 방식이 합리적이다.

---

## 8. 마무리: 빅데이터 시대에 기억해 두고 싶은 한 문장들

정리해 두고 싶은 문장만 몇 개 남긴다면:

- **빅데이터** 는 원유이고,  
  **통계·머신러닝·시각화·추천 시스템** 은  
  그 원유를 제품으로 바꾸는 정제·가공 기술이다.

- 전통 통계는 **절차와 인과** 를 중시하고,  
  빅데이터/머신러닝은 **상관관계와 예측력** 을 중시한다.  
  둘 중 하나가 “정답”이 아니라,  
  **문제에 따라 어떤 관점이 더 맞는지 고르는 것**이 중요하다.

- 시각화의 핵심은  
  **정직(Honesty)·간결(Simplicity)·정확(Accuracy)** 이다.

- 추천 시스템은  
  “**내가 좋아할 만한 것을 찾는 것**”과  
  “**새로운 것을 발견하게 하는 것**” 사이의 균형을 고민해야 한다.  
  Precision과 Recall은 그 균형을 수치로 보여주는 도구다.

